<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Unsupervised LULC Classification Workflow</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&family=Montserrat:wght@400;700&display=swap" rel="stylesheet">
    <style>
        /* Global Styles */
        :root {
            --primary-blue: #007bff;
            --dark-blue: #0056b3;
            --light-gray: #f8f9fa;
            --medium-gray: #e9ecef;
            --text-dark: #343a40;
            --text-medium: #6c757d;
            --whatsapp-green: #25D366;
            --whatsapp-green-dark: #1DA851;
            --shadow-light: rgba(0, 0, 0, 0.08);
            --shadow-medium: rgba(0, 0, 0, 0.15);
        }

        body {
            font-family: 'Roboto', sans-serif;
            line-height: 1.7;
            margin: 0;
            padding-bottom: 100px;
            background-color: var(--light-gray);
            color: var(--text-dark);
            user-select: none;
            -webkit-user-select: none;
            -moz-user-select: none;
            -ms-user-select: none;
        }

        header {
            background: linear-gradient(135deg, #1f4287 0%, #2196f3 100%);
            color: white;
            text-align: center;
            padding: 3rem 1rem;
            box-shadow: 0 4px 15px var(--shadow-medium);
            animation: fadeIn 1s ease-out;
        }

        header h1 {
            font-family: 'Montserrat', sans-serif;
            font-size: 2.8em;
            margin: 0 0 0.5rem 0;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.2);
        }

        header p {
            font-size: 1.1em;
            opacity: 0.9;
            max-width: 700px;
            margin: 0 auto;
        }

        main {
            max-width: 960px;
            margin: 2rem auto;
            padding: 0 1rem;
        }

        .workflow-section {
            background-color: white;
            padding: 2.5rem;
            margin-bottom: 2rem;
            border-radius: 10px;
            box-shadow: 0 6px 20px var(--shadow-light);
            transition: transform 0.3s ease-out, box-shadow 0.3s ease-out;
            border-left: 8px solid var(--primary-blue);
            animation: slideIn 0.8s ease-out forwards;
            opacity: 0;
        }

        .workflow-section:hover {
            transform: translateY(-5px);
            box-shadow: 0 8px 25px var(--shadow-medium);
        }

        .step-heading {
            font-family: 'Montserrat', sans-serif;
            font-size: 1.8em;
            color: var(--dark-blue);
            margin-top: 0;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid var(--medium-gray);
        }

        .step-description {
            font-size: 1.05em;
            margin-bottom: 1.5rem;
            color: var(--text-dark);
        }

        .image-container {
            position: relative;
            margin: 1.5rem 0;
        }

        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 0 auto;
            border-radius: 8px;
            box-shadow: 0 4px 12px var(--shadow-light);
            transition: transform 0.3s ease-out;
            pointer-events: none;
        }

        img:hover {
            transform: scale(1.01);
        }

        .image-caption {
            font-size: 0.9em;
            color: var(--text-medium);
            text-align: center;
            margin-top: 0.5rem;
        }

        footer {
            text-align: center;
            padding: 2rem;
            margin-top: 3rem;
            background-color: var(--medium-gray);
            color: var(--text-medium);
            font-size: 0.9em;
            border-top: 1px solid #dee2e6;
        }

        #whatsapp-button {
            position: fixed;
            bottom: 25px;
            right: 25px;
            background-color: var(--whatsapp-green);
            color: white;
            font-size: 28px;
            width: 60px;
            height: 60px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 6px 20px var(--shadow-medium);
            cursor: pointer;
            z-index: 1000;
            transition: all 0.3s ease-in-out;
        }

        #whatsapp-button:hover {
            background-color: var(--whatsapp-green-dark);
            transform: scale(1.1) translateY(-3px);
            box-shadow: 0 8px 25px rgba(0,0,0,0.4);
        }

        #chat-box {
            display: none;
            position: fixed;
            bottom: 100px;
            right: 25px;
            background: white;
            width: 320px;
            border-radius: 12px;
            box-shadow: 0 8px 30px var(--shadow-medium);
            z-index: 999;
            overflow: hidden;
            animation: slideInRight 0.4s ease-out forwards;
        }

        .chat-header {
            background: var(--whatsapp-green);
            color: white;
            padding: 15px 20px;
            font-weight: 700;
            text-align: center;
            font-size: 1.2em;
        }

        .chat-body {
            padding: 20px;
        }

        .chat-body textarea {
            width: calc(100% - 20px);
            height: 120px;
            resize: vertical;
            border-radius: 8px;
            border: 1px solid #ddd;
            padding: 10px;
            font-size: 1em;
            line-height: 1.5;
            box-shadow: inset 0 1px 3px rgba(0,0,0,0.05);
            transition: border-color 0.2s ease, box-shadow 0.2s ease;
        }

        .chat-body textarea:focus {
            border-color: var(--primary-blue);
            box-shadow: inset 0 1px 3px rgba(0,0,0,0.1), 0 0 0 3px rgba(0, 123, 255, 0.25);
            outline: none;
        }

        .chat-body button {
            margin-top: 15px;
            float: right;
            background: var(--whatsapp-green);
            color: white;
            border: none;
            padding: 12px 25px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 1.05em;
            font-weight: 600;
            transition: background-color 0.2s ease, transform 0.2s ease, box-shadow 0.2s ease;
            box-shadow: 0 2px 8px rgba(0,0,0,0.15);
        }

        .chat-body button:hover {
            background-color: var(--whatsapp-green-dark);
            transform: translateY(-1px);
            box-shadow: 0 4px 10px rgba(0,0,0,0.25);
        }

        .chat-body button:active {
            transform: translateY(0);
            box-shadow: inset 0 1px 3px rgba(0,0,0,0.2);
        }

        @keyframes fadeIn {
            from { opacity: 0; }
            to { opacity: 1; }
        }

        @keyframes slideIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        @keyframes slideInRight {
            from { opacity: 0; transform: translateX(50px); }
            to { opacity: 1; transform: translateX(0); }
        }

        @media (max-width: 768px) {
            header h1 { font-size: 2em; }
            .workflow-section { padding: 1.5rem; margin-bottom: 1.5rem; }
            .step-heading { font-size: 1.5em; }
            #whatsapp-button { bottom: 15px; right: 15px; width: 50px; height: 50px; font-size: 24px; }
            #chat-box { bottom: 80px; right: 15px; width: calc(100% - 30px); max-width: 320px; }
            .chat-body textarea { height: 100px; }
        }
    </style>
</head>
<body oncontextmenu="return false">
    <header>
        <h1>Unsupervised Land Use/Land Cover Classification Workflow</h1>
        <p>A detailed workflow for unsupervised classification using ENVI and ArcMap, focusing on digital image analysis for geospatial applications.</p>
    </header>

    <main id="steps"></main>

    <footer>
        <p>Developed by: Kimathi Joram</p>
        <p>© 2025. All rights reserved.</p>
    </footer>

    <div id="whatsapp-button" title="Contact via WhatsApp">
        <svg viewBox="0 0 24 24" width="24" height="24" fill="currentColor">
            <path d="M12.04 2c-5.45 0-9.91 4.46-9.91 9.91 0 1.75.5 3.44 1.45 4.96L2 22l5.25-1.38c1.45.79 3.09 1.25 4.79 1.25 5.45 0 9.91-4.46 9.91-9.91S17.49 2 12.04 2zm.05 1.5c4.61 0 8.38 3.77 8.38 8.38 0 4.61-3.77 8.38-8.38 8.38-1.57 0-3.1-.43-4.41-1.18l-.3-.17-3.13.82.83-3.04-.2-.3c-.86-1.47-1.32-3.16-1.32-4.93 0-4.61 3.77-8.38 8.38-8.38zm-3.41 4.72c-.22 0-.44.07-.63.2-.23.16-.65.64-.65 1.55 0 .91.67 1.76.77 1.88.1.12 1.34 2.15 3.25 2.94 1.91.79 2.3 1.05 2.73.97.43-.09 1.34-.55 1.54-1.09.2-.53.2-1.02.14-1.15-.06-.13-.23-.2-.48-.32-.25-.12-1.54-.76-1.78-.85-.24-.09-.43-.03-.63.2-.2.24-.76.97-1.02 1.25-.26.28-.5.31-.92.1-.42-.2-1.76-.65-2.22-1.4-.46-.75-.05-1.16.32-1.45.3-.24.4-.38.53-.6.13-.22.07-.41-.02-.57-.09-.16-.65-1.54-.89-2.1c-.25-.57-.49-.48-.65-.48z"/>
        </svg>
    </div>
    <div id="chat-box">
        <div class="chat-header">Contact via WhatsApp</div>
        <div class="chat-body">
            <textarea id="chat-message" placeholder="Type your message here..."></textarea>
            <button onclick="sendMessage()">Send</button>
        </div>
    </div>

    <script>
        const steps = [
            {
                title: "Step 1: Launching ENVI for Geospatial Processing",
                description: "Open ENVI (preferably 32-bit for compatibility with older datasets) to process multispectral or hyperspectral imagery. Ensure the system supports ENVI's requirements for handling large raster datasets used in remote sensing analysis.",
                images: [
                    { src: "1.png", caption: "ENVI interface ready for geospatial image processing." }
                ]
            },
            {
                title: "Step 2: Importing Satellite Imagery",
                description: "Navigate to File → Open and select your satellite image (e.g., Landsat 8 image for Kericho, 2015). ENVI supports formats like TIFF, IMG, or ENVI native formats. This step loads the raster data, enabling spectral analysis of pixel values.",
                images: [
                    { src: "2.png", caption: "Selecting the satellite image in ENVI." },
                    { src: "3.png", caption: "File browser showing supported raster formats." }
                ]
            },
            {
                title: "Step 3: Visualizing Image Data",
                description: "The loaded image appears in ENVI's viewport, typically as an RGB composite of spectral bands. Verify spatial resolution, band wavelengths, and georeferencing to ensure the data is suitable for unsupervised classification.",
                images: [
                    { src: "4.png", caption: "Multispectral image displayed in ENVI viewport." }
                ]
            },
            {
                title: "Step 4: Accessing the Classification Workflow",
                description: "In the ENVI Toolbox, select Classification → Workflow to start unsupervised classification. This tool uses algorithms like ISODATA to cluster pixels based on spectral signatures without requiring training data.",
                images: [
                    { src: "5.png", caption: "ENVI Toolbox with Classification Workflow selected." }
                ]
            },
            {
                title: "Step 5: Configuring Unsupervised Classification Parameters",
                description: "In the Classification Workflow, select 'No Training Data' for unsupervised classification. Choose the ISODATA algorithm, which groups pixels into clusters based on spectral similarity. Confirm the input file and proceed to set parameters.",
                images: [
                    { src: "6.png", caption: "Classification Workflow setup for unsupervised method." },
                    { src: "7.png", caption: "Confirming input file for classification." }
                ]
            },
            {
                title: "Step 6: Defining Output Classes",
                description: "In the ISODATA Parameters window, set the number of classes (e.g., 7) to represent land cover types like forest, water, or urban areas. This accounts for potential unclassified pixels. The algorithm iteratively clusters pixels based on their spectral reflectance.",
                images: [
                    { src: "8.png", caption: "Setting 7 classes in ISODATA parameters." },
                    { src: "9.png", caption: "Preview of initial spectral clusters." }
                ]
            },
            {
                title: "Step 7: Refining and Exporting Classified Data",
                description: "After clustering, apply a 7x7 smoothing kernel to reduce noise and enhance spatial coherence in the classified image. Export the smoothed raster to a folder in a format like TIFF, ready for further analysis in ArcMap.",
                images: [
                    { src: "10.png", caption: "Initial classified image before smoothing." },
                    { src: "11.png", caption: "Smoothed classification with 7x7 kernel applied." },
                    { src: "12.png", caption: "Exporting the classified raster to a folder." }
                ]
            },
            {
                title: "Step 8: Importing Classified Image into ArcMap",
                description: "Open ArcMap and add the exported classified raster. Ensure the coordinate system aligns with the original image for accurate spatial analysis and cartographic visualization.",
                images: [
                    { src: "A1.png", caption: "Adding the classified image to ArcMap." }
                ]
            },
            {
                title: "Step 9: Addressing Unclassified Regions in ArcMap",
                description: "In ArcMap, inspect the classified image for unclassified pixels, which may result from spectral ambiguity. Assign 'no color' to these areas in the symbology settings to focus on defined land cover classes.",
                images: [
                    { src: "A2.png", caption: "Classified image with unclassified pixels highlighted." }
                ]
            },
            {
                title: "Step 10: Refining Symbology and Class Definition",
                description: "In ArcMap's Properties → Symbology, apply a custom color ramp or True Color relation to visualize land cover classes (e.g., vegetation, water, urban). Reference the original RGB composite to assign meaningful labels to each class.",
                images: [
                    { src: "A3.png", caption: "Symbology settings in ArcMap for class visualization." },
                    { src: "A4.png", caption: "True Color visualization of classified land cover classes." }
                ]
            },
            {
                title: "Step 11: Final Land Use/Land Cover Mapping",
                description: "Finalize the LULC map by interpreting the 5 distinct land cover classes derived from unsupervised classification. This methodology was applied to Landsat images from 1985, 1995, 2005, 2015, and 2025 for Kericho, Kenya, enabling temporal analysis of land cover changes.",
                images: [
                    { src: "A5.png", caption: "Final LULC map with 5 interpreted land cover classes." }
                ]
            }
        ];

        const stepsContainer = document.getElementById("steps");

        steps.forEach((step, index) => {
            const section = document.createElement("section");
            section.className = "workflow-section";
            section.style.animationDelay = `${index * 0.2}s`; // Staggered animation

            const heading = document.createElement("h2");
            heading.className = "step-heading";
            heading.textContent = step.title;
            section.appendChild(heading);

            const description = document.createElement("p");
            description.className = "step-description";
            description.textContent = step.description;
            section.appendChild(description);

            step.images.forEach(img => {
                const container = document.createElement("div");
                container.className = "image-container";
                const image = document.createElement("img");
                image.src = `images/${img.src}`;
                image.alt = img.caption;
                image.onerror = () => {
                    image.src = "images/placeholder.png"; // Fallback image
                    image.alt = "Image not found";
                };
                container.appendChild(image);
                const caption = document.createElement("p");
                caption.className = "image-caption";
                caption.textContent = img.caption;
                container.appendChild(caption);
                section.appendChild(container);
            });

            stepsContainer.appendChild(section);
        });

        document.getElementById("whatsapp-button").onclick = () => {
            const chat = document.getElementById("chat-box");
            chat.style.display = chat.style.display === "block" ? "none" : "block";
        };

        function sendMessage() {
            const msg = document.getElementById("chat-message").value.trim();
            if (msg) {
                const url = `https://wa.me/254101370035?text=${encodeURIComponent(msg)}`;
                window.open(url, '_blank');
                document.getElementById("chat-message").value = '';
                document.getElementById("chat-box").style.display = "none";
            } else {
                alert("Please type a message before sending.");
            }
        }
    </script>
</body>
</html>
<!-- <!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Advanced Geospatial Analysis: Unsupervised Classification Workflow</title>
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&family=Montserrat:wght@400;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary-color: #007bff;
            --secondary-color: #6c757d;
            --accent-color: #28a745;
            --background-light: #f8f9fa;
            --background-dark: #e9ecef;
            --text-color: #343a40;
            --heading-color: #0056b3;
            --border-color: #dee2e6;
            --shadow-light: rgba(0, 0, 0, 0.05);
            --shadow-medium: rgba(0, 0, 0, 0.1);
        }

        body {
            font-family: 'Roboto', sans-serif;
            line-height: 1.7;
            margin: 0;
            padding: 0;
            background-color: var(--background-light);
            color: var(--text-color);
            scroll-behavior: smooth;
        }

        .container {
            max-width: 960px;
            margin: 30px auto;
            background: #fff;
            padding: 40px;
            border-radius: 12px;
            box-shadow: 0 8px 20px var(--shadow-medium);
            animation: fadeIn 1s ease-out;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(20px); }
            to { opacity: 1; transform: translateY(0); }
        }

        header {
            text-align: center;
            margin-bottom: 40px;
            padding-bottom: 20px;
            border-bottom: 3px solid var(--primary-color);
        }

        header h1 {
            font-family: 'Montserrat', sans-serif;
            font-size: 3.2em;
            color: var(--heading-color);
            margin-bottom: 10px;
            text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.05);
        }

        header p {
            font-size: 1.2em;
            color: var(--secondary-color);
            max-width: 700px;
            margin: 0 auto;
        }

        h2, h3 {
            font-family: 'Montserrat', sans-serif;
            color: var(--heading-color);
            margin-top: 40px;
            margin-bottom: 20px;
            padding-bottom: 8px;
            border-bottom: 1px solid var(--border-color);
        }

        h2 {
            font-size: 2.2em;
            border-left: 8px solid var(--primary-color);
            padding-left: 15px;
            animation: slideInLeft 0.8s ease-out;
        }

        h3 {
            font-size: 1.6em;
            color: var(--primary-color);
            border-bottom: none;
            position: relative;
            padding-bottom: 5px;
        }

        h3::after {
            content: '';
            position: absolute;
            left: 0;
            bottom: 0;
            width: 50px;
            height: 3px;
            background-color: var(--accent-color);
            border-radius: 2px;
        }

        @keyframes slideInLeft {
            from { opacity: 0; transform: translateX(-50px); }
            to { opacity: 1; transform: translateX(0); }
        }

        .section {
            margin-bottom: 40px;
        }

        .step {
            background-color: var(--background-dark);
            border-left: 6px solid var(--primary-color);
            padding: 25px;
            margin-bottom: 30px;
            border-radius: 8px;
            box-shadow: 0 4px 10px var(--shadow-light);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
            position: relative;
            overflow: hidden;
        }

        .step:hover {
            transform: translateY(-5px);
            box-shadow: 0 6px 15px var(--shadow-medium);
        }

        .step::before {
            content: counter(step-counter);
            counter-increment: step-counter;
            position: absolute;
            top: 20px;
            right: 20px;
            background-color: var(--primary-color);
            color: white;
            border-radius: 50%;
            width: 40px;
            height: 40px;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.4em;
            font-weight: bold;
            box-shadow: 0 2px 5px var(--shadow-medium);
        }

        .step img {
            max-width: 100%;
            height: auto;
            border: 1px solid var(--border-color);
            border-radius: 6px;
            margin-top: 20px;
            margin-bottom: 20px;
            display: block;
            margin-left: auto;
            margin-right: auto;
            box-shadow: 0 2px 8px var(--shadow-light);
            transition: transform 0.4s ease;
        }

        .step img:hover {
            transform: scale(1.02);
        }

        .caption {
            font-size: 0.9em;
            color: var(--secondary-color);
            text-align: center;
            margin-top: -10px;
            margin-bottom: 20px;
            font-style: italic;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 25px 0;
            box-shadow: 0 2px 8px var(--shadow-light);
            border-radius: 8px;
            overflow: hidden; /* Ensures border-radius is applied to children */
        }
        table, th, td {
            border: 1px solid var(--border-color);
        }
        th, td {
            padding: 12px 15px;
            text-align: left;
        }
        th {
            background-color: var(--primary-color);
            color: white;
            font-family: 'Montserrat', sans-serif;
            font-weight: 700;
        }
        tr:nth-child(even) {
            background-color: var(--background-dark);
        }
        tr:hover {
            background-color: #f0f0f0;
        }

        .highlight {
            background-color: rgba(0, 123, 255, 0.1);
            padding: 2px 6px;
            border-radius: 4px;
            font-weight: bold;
            color: var(--primary-color);
        }

        footer {
            text-align: center;
            margin-top: 50px;
            padding-top: 25px;
            border-top: 1px solid var(--border-color);
            font-size: 0.85em;
            color: var(--secondary-color);
        }

        /* Responsive Design */
        @media (max-width: 768px) {
            .container {
                margin: 15px;
                padding: 20px;
            }
            header h1 {
                font-size: 2.5em;
            }
            h2 {
                font-size: 1.8em;
            }
            h3 {
                font-size: 1.3em;
            }
            .step::before {
                width: 30px;
                height: 30px;
                font-size: 1.1em;
            }
        }

        /* WhatsApp Button Styles */
        .whatsapp-button-container {
            text-align: center;
            margin-top: 30px;
            margin-bottom: 30px;
        }

        .whatsapp-button {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            background-color: #25D366; /* WhatsApp Green */
            color: white;
            padding: 12px 25px;
            border-radius: 30px;
            text-decoration: none;
            font-family: 'Roboto', sans-serif;
            font-size: 1.1em;
            font-weight: bold;
            transition: background-color 0.3s ease, transform 0.2s ease;
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
        }

        .whatsapp-button:hover {
            background-color: #1DA851;
            transform: translateY(-2px);
        }

        .whatsapp-button svg {
            margin-right: 10px;
            width: 24px;
            height: 24px;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Advanced Geospatial Analysis: Unsupervised Classification Workflow</h1>
            <p>A comprehensive guide detailing the process of performing unsupervised Land Use/Land Cover (LULC) classification using ENVI software, and subsequently refining and visualizing the results within ArcMap. This methodology is crucial for dynamic environmental monitoring and land management studies in regions like Kericho, Kenya.</p>
        </header>

        <section class="section">
            <h2>Part 1: Unsupervised Classification in ENVI</h2>
            <p>This section outlines the initial phase of image processing, focusing on how raw satellite imagery is transformed into thematic land cover maps using ENVI's robust unsupervised classification algorithms.</p>

            <div class="step">
                <h3>Step 1: Initiating ENVI Software</h3>
                <p>Begin by launching the ENVI software on your computing device. For optimal compatibility and to facilitate seamless integration with ArcMap for subsequent cartographic refinements, it is highly recommended to use the <span class="highlight">32-bit version of ENVI 5.3</span>. This specific version provides critical export functionalities that streamline the workflow between the two platforms.</p>
                <img src="images/1.png" alt="Opening ENVI 5.3 (32-bit)">
                <p class="caption">Figure 1: Locating and launching the ENVI 5.3 (32-bit) application through the system search interface.</p>
            </div>

            <div class="step">
                <h3>Step 2: Importing Satellite Imagery into ENVI</h3>
                <p>Upon successful launch, the ENVI graphical user interface will appear. To load your satellite imagery for analysis, navigate to the menu bar and select <span class="highlight">File > Open</span>. This action will prompt a file browser, allowing you to locate and select your desired image file. ENVI supports a variety of common raster formats, including <span class="highlight">.TIF, .IMG, and .OVR</span> files.</p>
                <img src="images/2.png" alt="ENVI Open File Interface">
                <p class="caption">Figure 2: The ENVI main interface, illustrating the "File" menu and the "Open" option selected to import data.</p>
                <img src="images/3.png" alt="Browse for Image File in ENVI">
                <p class="caption">Figure 3: A file explorer window demonstrating the selection of a Landsat 8 image for Kericho County (e.g., "KERICHO COUNTY FROM 2015-01-01 TO 2015-12-31 LANDSAT8").</p>
            </div>

            <div class="step">
                <h3>Step 3: Accessing the Classification Workflow</h3>
                <p>Once the image is successfully loaded, it will be rendered within the ENVI viewport. For instance, the Kericho Landsat 8 image from 2015 is now ready for processing. To initiate the unsupervised classification process, direct your attention to the <span class="highlight">ENVI Toolbox</span>, typically situated in the upper-right section of the interface. Expand the <span class="highlight">Classification</span> category, and then select <span class="highlight">Classification Workflow</span> to proceed.</p>
                <img src="images/4.png" alt="Loaded Image and Classification Workflow Selection">
                <p class="caption">Figure 4: The ENVI environment showing the loaded image and the highlighted path to the "Classification Workflow" within the Toolbox.</p>
            </div>

            <div class="step">
                <h3>Step 4: Defining Input and Classification Method</h3>
                <p>The "File Selection" dialogue will appear, where you must confirm that the correct input raster file is chosen for classification. Subsequently, you will be presented with the "Classification Type" window. A key characteristic of unsupervised classification is its independence from predefined training samples; the algorithm autonomously groups pixels based on their spectral properties. Therefore, select the <span class="highlight">"No Training Data"</span> option and proceed to the next step.</p>
                <img src="images/5.png" alt="File Selection and No Training Data Option">
                <p class="caption">Figure 5: Specifying the input file and selecting "No Training Data" for unsupervised classification.</p>
            </div>

            <div class="step">
                <h3>Step 5: Specifying Number of Classes with ISODATA Parameters</h3>
                <p>In the "Unsupervised Classification ISODATA Parameters" window, you are required to define the desired number of thematic classes (or clusters) that the ISODATA algorithm will attempt to identify within the imagery. In this specific case, <span class="highlight">seven classes were assigned</span>. This choice accounts for the possibility that two of these initial clusters might represent "Unclassified" or "No-data" regions, leaving a more manageable number of meaningful land cover categories for subsequent analysis.</p>
                <img src="images/6.png" alt="ISODATA Parameters - Number of Classes">
                <p class="caption">Figure 6: The "ISODATA Parameters" window, showing the input field for "Number of Classes" set to 7.</p>
            </div>

            <div class="step">
                <h3>Step 6: Refining Classification Results (Cleanup)</h3>
                <p>Once the unsupervised classification process concludes, the image with its extracted thematic classes will be displayed. To enhance the visual quality and spatial coherence of the classification, the "Cleanup" window provides options for refinement. This includes enabling <span class="highlight">"Enable Smoothing"</span> and <span class="highlight">"Enable Aggregation"</span>. For smoothing, a filter matrix such as a $7 \times 7$ kernel was applied, which helps in reducing salt-and-pepper noise and producing more generalized land cover patches.</p>
                <img src="images/7.png" alt="Cleanup - Refine Results">
                <p class="caption">Figure 7: The "Cleanup" interface, illustrating the options for refining the classification output, including smoothing and aggregation parameters.</p>
            </div>

            <div class="step">
                <h3>Step 7: Exporting Classification Outputs</h3>
                <p>After the refinement process, the "cleaned" image can be exported for further manipulation and cartographic production in other geospatial software, notably ArcMap. Select the <span class="highlight">"Export Classification Image"</span> option and specify your preferred output format (e.g., ENVI) and the desired filename and directory. Additionally, the classified features can be exported as <span class="highlight">"Classification Vectors"</span> (e.g., in Shapefile format), which provides vector data suitable for detailed GIS analysis.</p>
                <img src="images/8.png" alt="Export Save Results">
                <p class="caption">Figure 8: The "Export Save Results" window, showing options for exporting both raster classification images and vector features.</p>
                <img src="images/9.png" alt="Exporting Results Progress">
                <p class="caption">Figure 9: A progress bar indicating the ongoing export of the classification results to the specified output folder.</p>
            </div>
        </section>

        <section class="section">
            <h2>Part 2: Refinement and Cartographic Enhancements in ArcMap</h2>
            <p>This section details the critical steps taken in ArcMap to transform the raw classified output into a polished, cartographically sound LULC map, including reclassification and symbology adjustments.</p>

            <div class="step">
                <h3>Step 1: Importing Classified Image into ArcMap</h3>
                <p>With the classification results successfully exported from ENVI, the subsequent step involves adding this classified image to the ArcMap viewport. This is achieved by using the "Add Data" tool within ArcMap and navigating to the location where your exported `.dat` (or other raster format) file is saved.</p>
                <img src="images/A1.png" alt="Adding Exported Image to ArcMap">
                <p class="caption">Figure A1: The ArcMap interface, demonstrating the process of adding the exported classified image (e.g., `demo.dat`) to the map document.</p>
            </div>

            <div class="step">
                <h3>Step 2: Initial Observation of Unclassified Regions</h3>
                <p>Upon adding the image to ArcMap, you will likely observe that certain areas are initially designated as "Unclassified". These unclassified pixels typically represent areas that the unsupervised algorithm could not confidently assign to a distinct spectral class, or they might be background noise. Identifying these areas is crucial for the subsequent reclassification process.</p>
                <img src="images/A2.png" alt="Image in ArcMap with Unclassified Classes">
                <p class="caption">Figure A2: The classified image as it first appears in ArcMap, highlighting the presence of initial unclassified regions.</p>
            </div>

            <div class="step">
                <h3>Step 3: Relating Thematic Classes and Symbology Adjustments</h3>
                <p>To establish meaningful land cover categories, access the image's properties in ArcMap, specifically the <span class="highlight">Symbology</span> tab. Here, you can visually correlate the spectrally derived unsupervised classes with the true color composite of the original raw Landsat 8 image. This comparative analysis allows for the assignment of appropriate real-world land cover labels to the classified clusters. A practical first step is to render the "Unclassified" categories with "no color" to clearly delineate the actual classified areas for visual assessment.</p>
                <img src="images/A3.png" alt="ArcMap Properties - Symbology">
                <p class="caption">Figure A3: ArcMap Layer Properties window, illustrating how symbology can be adjusted in relation to the original true color composite image for accurate class identification.</p>
                <img src="images/A4.png" alt="Unclassified Classes Turned to No Color">
                <p class="caption">Figure A4: The classified image in ArcMap after applying a "no color" symbology to the unclassified pixels, improving the clarity of the defined land cover types.</p>
            </div>

            <div class="step">
                <h3>Step 4: Final Classification and Cartographic Naming</h3>
                <p>Based on the visual interpretation and correlation with the reference imagery, the initial unsupervised classes are refined into definitive Land Use/Land Cover categories. For this study, five distinct LULC classes were identified and assigned specific colors for cartographic representation.</p>
                <p>The final mapping scheme for the LULC categories is presented below:</p>
                <table>
                    <thead>
                        <tr>
                            <th>Color Legend</th>
                            <th>LULC Category</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><span style="background-color: #7CFC00; display: inline-block; width: 20px; height: 20px; vertical-align: middle; margin-right: 5px; border: 1px solid #ccc;"></span> Medium Apple</td>
                            <td>Vegetation</td>
                        </tr>
                        <tr>
                            <td><span style="background-color: #008080; display: inline-block; width: 20px; height: 20px; vertical-align: middle; margin-right: 5px; border: 1px solid #ccc;"></span> Peacock Green</td>
                            <td>Forest</td>
                        </tr>
                        <tr>
                            <td><span style="background-color: #FFCC99; display: inline-block; width: 20px; height: 20px; vertical-align: middle; margin-right: 5px; border: 1px solid #ccc;"></span> Cantaloupe</td>
                            <td>Bare</td>
                        </tr>
                        <tr>
                            <td><span style="background-color: #FF0000; display: inline-block; width: 20px; height: 20px; vertical-align: middle; margin-right: 5px; border: 1px solid #ccc;"></span> Fire Red</td>
                            <td>Built-up</td>
                        </tr>
                        <tr>
                            <td><span style="background-color: #9ACD32; display: inline-block; width: 20px; height: 20px; vertical-align: middle; margin-right: 5px; border: 1px solid #ccc;"></span> Lemon Grass</td>
                            <td>Other Agri-land</td>
                        </tr>
                    </tbody>
                </table>
                <img src="images/A5.png" alt="Final Classified Map in ArcMap">
                <p class="caption">Figure A5: The finalized LULC map in ArcMap, showing the distinct five classified categories after refinement and renaming.</p>
            </div>
        </section>

        <section class="section">
            <h2>Conclusion & Application</h2>
            <p>
                This meticulously documented workflow provides a robust framework for performing unsupervised classification using ENVI and subsequent cartographic refinement in ArcMap. This comprehensive process, from initial image acquisition and classification in ENVI to the nuanced reclassification and symbology adjustments in ArcMap, was systematically applied to satellite imagery of Kericho, Kenya, spanning the years 1985, 1995, 2005, 2015, and 2025. The resulting Land Use/Land Cover maps serve as invaluable tools for monitoring environmental changes, urban expansion, and agricultural dynamics over time within the region.
            </p>
        </section>

        <section class="whatsapp-button-container">
            <a href="https://wa.me/254101370035?text=Hello%2C%20I%20have%20a%20question%20about%20your%20unsupervised%20classification%20procedures." class="whatsapp-button" target="_blank" rel="noopener noreferrer">
                <svg viewBox="0 0 24 24" width="24" height="24" fill="currentColor">
                    <path d="M12.04 2c-5.45 0-9.91 4.46-9.91 9.91 0 1.75.5 3.44 1.45 4.96L2 22l5.25-1.38c1.45.79 3.09 1.25 4.79 1.25 5.45 0 9.91-4.46 9.91-9.91S17.49 2 12.04 2zm.05 1.5c4.61 0 8.38 3.77 8.38 8.38 0 4.61-3.77 8.38-8.38 8.38-1.57 0-3.1-.43-4.41-1.18l-.3-.17-3.13.82.83-3.04-.2-.3c-.86-1.47-1.32-3.16-1.32-4.93 0-4.61 3.77-8.38 8.38-8.38zm-3.41 4.72c-.22 0-.44.07-.63.2-.23.16-.65.64-.65 1.55 0 .91.67 1.76.77 1.88.1.12 1.34 2.15 3.25 2.94 1.91.79 2.3 1.05 2.73.97.43-.09 1.34-.55 1.54-1.09.2-.53.2-1.02.14-1.15-.06-.13-.23-.2-.48-.32-.25-.12-1.54-.76-1.78-.85-.24-.09-.43-.03-.63.2-.2.24-.76.97-1.02 1.25-.26.28-.5.31-.92.1-.42-.2-1.76-.65-2.22-1.4-.46-.75-.05-1.16.32-1.45.3-.24.4-.38.53-.6.13-.22.07-.41-.02-.57-.09-.16-.65-1.54-.89-2.1c-.25-.57-.49-.48-.65-.48z"/>
                </svg>
                Chat on WhatsApp
            </a>
        </section>

        <footer>
            <p>Created by: KIMATHI JORAM</p>
            <p>&copy; 2025. All rights reserved.</p>
        </footer>
    </div>
</body>
</html> -->
